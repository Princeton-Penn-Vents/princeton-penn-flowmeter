import abc
import enum
import threading
import time
import warnings

import numpy as np
from datetime import datetime
from typing import Dict, Any, List, Optional, Sequence, TypeVar
from pathlib import Path

import processor.analysis
from processor.rotary import LocalRotary
from processor.settings import get_remote_settings


class Status(enum.Enum):
    OK = enum.auto()
    ALERT = enum.auto()
    DISCON = enum.auto()


COLOR = {
    Status.OK: (151, 222, 121),
    Status.ALERT: (237, 67, 55),
    Status.DISCON: (50, 50, 220),
}


T = TypeVar("T", bound="Generator")


class Generator(abc.ABC):
    WINDOW_SIZE = 50 * 30  # 50 hz * 30 seconds

    def __init__(self, *, rotary: processor.rotary.LocalRotary = None) -> None:
        # The volume, expected to be generated by ._analyze_timeseries()
        self._volume = np.array([], dtype=np.double)

        # The previous collection of realtime values, as floats
        self._old_realtime: Optional[np.ndarray] = None

        # The minimum volume (JP?)
        self._volume_unshifted_min: Optional[float] = None

        # The amount to shift the volume (JP?)
        self._volume_shift = 0.0

        # The cumulative running windows for flow
        self._flow_cumulative = {
            1: 0.0,
            3: 0.0,
            5: 0.0,
            10: 0.0,
            20: 0.0,
            30: 0.0,
            60: 0.0,
        }

        # The cumulative running windows for pressure
        self._pressure_cumulative = {
            1: 0.0,
            3: 0.0,
            5: 0.0,
            10: 0.0,
            20: 0.0,
            30: 0.0,
            60: 0.0,
        }

        # The list of breaths
        self._breaths: List[Any] = []

        # The list of cumulative values from the analysis
        self._cumulative: Dict[str, float] = {}

        # The cumulative timestamps (JP?)
        self._cumulative_timestamps: Dict[str, Any] = {}

        # JP?
        self._window_cumulative: Dict[str, Any] = {}

        # The active alarms
        self._alarms: Dict[str, Dict[str, float]] = {}

        # The rotary with alarm settings
        self.rotary = LocalRotary(get_remote_settings()) if rotary is None else rotary

        # How often to rerun analyze (full analyze)
        self.analyze_every = 3  # seconds

        # How often to process data in automatic mode (partial analyze)
        self.run_every = 0.5  # seconds

        # Last updated datetime.now()
        self.last_update: Optional[float] = None

        # Last analyze run in local time - used by analyze_as_needed
        self._last_ana = time.monotonic()

        # Last partial analyze for plotting
        self._last_get: Optional[float] = None

        # Status of the generator alarms, set in get_data
        self.status: Status

        # Path to write data to (needs name change)
        self._logging: Optional[Path] = None

        # This lock ensures validity of the access when threading.
        # This may be "reentered" by analyze calling the properties; that is fine.
        self.lock = threading.RLock()

        # A thread to run the analyze loop in the background
        self._run_thread: Optional[threading.Thread] = None

        # A stop signal to turn off the thread
        self._stop = threading.Event()

    def run(self) -> None:
        """
        Start running an analysis loop. Calling get_data and analyze_as_needed manually are not recommended
        while this is running in the background. Be sure to close/exit context to close and clean up the thread.

        Started by the context manager
        """

        self._stop.clear()
        self._run_thread = threading.Thread(target=self._run)
        self._run_thread.start()

    def _run(self) -> None:
        """
        Must be run in the background, by run()
        """

        while not self._stop.is_set():
            with self.lock:
                self.get_data()
                self.analyze_as_needed()
            time.sleep(self.run_every)

    def analyze_as_needed(self) -> bool:
        """
        Run basic analysis, and more complex analysis only if needed.
        """
        if time.monotonic() - self._last_ana < self.analyze_every:
            self.analyze_timeseries()
            return False
        else:
            self.analyze()
            self._last_ana = time.monotonic()
            return True

    @abc.abstractmethod
    def get_data(self):
        """
        Copy in the remote/local datastream to internal cache.
        """

    def prepare(self, *, from_timestamp: Optional[float] = None) -> Dict[str, Any]:
        """
        Prepare a dict for transmission via json. Does *not* call `get_data()`
        """
        if from_timestamp is None:
            window = slice(min(len(self.timestamps), 50 * 5), None)
        elif from_timestamp == 0:
            window = slice(None)
        else:
            start = np.searchsorted(self.timestamps, from_timestamp, side="right")
            window = slice(start, None)

        return {
            "version": 1,
            "time": datetime.now().timestamp(),
            # "alarms": self.alarms,
            # "cumulative": self.cumulative,
            "rotary": self.rotary.to_dict(),
            "data": {
                "timestamps": self.timestamps[window].tolist(),
                "flows": self.flow[window].tolist(),
                "pressures": self.pressure[window].tolist(),
            },
        }

    def analyze_timeseries(self) -> None:
        """
        Quick analysis that's easier to run often, makes volume (run by `analyze` too)
        """
        realtime = self.realtime
        if len(realtime) > 0:
            if self._logging is not None:
                if self._logging.exists() and not self._logging.is_dir():
                    warnings.warn(f"{self._logging} is not a directory; not logging")
                else:
                    if not self._logging.exists():
                        self._logging.mkdir()

                    if self._old_realtime is None or len(self._old_realtime) == 0:
                        start_index = 0
                    else:
                        start_index = (
                            np.argmin(abs(realtime - self._old_realtime[-1])) + 1
                        )

                    with open(self._logging / f"time_{id(self)}.dat", "ba",) as file:
                        file.write(
                            (realtime[start_index:] * 1000).astype("<u8").tostring()
                        )

                    with open(self._logging / f"flow_{id(self)}.dat", "ba",) as file:
                        file.write(self.flow[start_index:].astype("<f4").tostring())

                    with open(self._logging / f"time_{id(self)}.dat", "ba",) as file:
                        file.write(self.pressure[start_index:].astype("<f4").tostring())

            self._flow_cumulative = processor.analysis.compute_cumulative(
                self._flow_cumulative.keys(), self.timestamps, self.flow
            )

            self._pressure_cumulative = processor.analysis.compute_cumulative(
                self._pressure_cumulative.keys(), self.timestamps, self.pressure
            )

            self._volume = processor.analysis.flow_to_volume(
                realtime,
                self._old_realtime,
                self.flow,
                self._volume - self._volume_shift,
            )
            self._old_realtime = realtime

            if self._volume_unshifted_min is None:
                self._volume_unshifted_min = np.min(self._volume)
            else:
                self._volume_unshifted_min = min(
                    self._volume_unshifted_min, np.min(self._volume)
                )

            self._volume_shift = (
                -self._volume_unshifted_min
                if self._volume_unshifted_min is not None
                else 0
            )
            self._volume = self._volume + self._volume_shift

    def analyze(self) -> None:
        """
        Full analysis of breaths.
        """
        self.analyze_timeseries()

        realtime = self.realtime

        updated = []
        new_breaths = []
        updated_fields = set()

        if len(realtime) > 0:
            breaths = processor.analysis.measure_breaths(
                realtime, self.flow, self.volume, self.pressure
            )

            if len(breaths) > 0:
                (
                    all_breaths,
                    updated,
                    new_breaths,
                ) = processor.analysis.combine_breaths(self._breaths, breaths)

                self._breaths = all_breaths[-30:]

                self._cumulative, updated_fields = processor.analysis.cumulative(
                    self._cumulative, updated, new_breaths
                )

        self._alarms = processor.analysis.add_alarms(
            self.rotary, updated, new_breaths, self._cumulative
        )

        timestamp = time.time()
        cumulative_timestamps = dict(self._cumulative_timestamps)
        cumulative_timestamps[""] = timestamp
        for field in updated_fields:
            cumulative_timestamps[field] = timestamp
        self._cumulative_timestamps = cumulative_timestamps

        stale_threshold = self.rotary["Stale Data Timeout"].value
        default = timestamp - stale_threshold
        stale = {}
        for field in self._cumulative:
            last_update_timediff = timestamp - self._cumulative_timestamps.get(
                field, default
            )
            if last_update_timediff >= stale_threshold:
                stale[field] = last_update_timediff
        if len(stale) > 0:
            self._alarms["Stale Data"] = stale

        if hasattr(self, "status"):
            if self.alarms and self.status == Status.OK:
                self.status = Status.ALERT
            elif not self.alarms and self.status == Status.ALERT:
                self.status = Status.OK

    @property
    def time(self) -> np.ndarray:
        """
        The time array, with the most rececnt time as 0, with an adjustment based on `last_update`. Mostly for plotting.
        """
        timestamps = self.timestamps

        tardy = (
            (time.monotonic() - self._last_get) if self._last_get is not None else 0.0
        )

        if len(timestamps) > 0:
            return -(timestamps - timestamps[-1]) / 1000 + tardy
        else:
            return timestamps

    @property
    def realtime(self) -> np.ndarray:
        """
        The actual time in seconds (arbitrary monotonic device clock)
        """
        return self.timestamps / 1000

    @property
    @abc.abstractmethod
    def timestamps(self) -> np.ndarray:
        """
        Raw timestamps.
        """
        pass

    @property
    @abc.abstractmethod
    def flow(self) -> np.ndarray:
        """
        Raw flow data.
        """
        pass

    @property
    @abc.abstractmethod
    def pressure(self) -> np.ndarray:
        """
        Raw pressure data.
        """
        pass

    @property
    def volume(self) -> np.ndarray:
        """
        Computed volume.
        """
        return self._volume

    @property
    def breaths(self) -> List[Any]:
        """
        The last 30 computed breaths.
        """
        return self._breaths

    @property
    def alarms(self) -> Dict[str, Dict[str, float]]:
        """
        A dictionary of alarms, each with first and last time, and extreme value.
        """
        return self._alarms

    @property
    def cumulative(self) -> Dict[str, float]:
        """
        A dictionary of resulting values, like RR, from the analysis.
        """
        return self._cumulative

    @property
    def cumulative_timestamps(self):
        """
        JP?
        """

        return self._cumulative_timestamps

    @property
    def average_flow(self) -> Dict[int, float]:
        """
        The cumulative running averages
        """
        return self._flow_cumulative

    @property
    def average_pressure(self) -> Dict[int, float]:
        """
        The cumulative running averages
        """
        return self._pressure_cumulative

    def close(self) -> None:
        """
        Always close or use a context manager if running threads!
        """
        self._stop.set()
        if self._run_thread is not None:
            self._run_thread.join()

    def __enter__(self: T) -> T:
        self.run()
        return self

    def __exit__(self, *exc) -> None:
        self.close()
